{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Multithreading vs Multiprocessing Pt2\n",
    "## An example for Data Scientist (NLP)\n",
    "## A Text Classifier\n",
    "\n",
    "This notebook presents how Python multiprocessing and multithreading can accelerate a simple NLP project.\n",
    "The project consists of a text classifier using a random forest model.\n",
    "\n",
    "If you are here just to see how multiprocessing and multithreading can be used in a real project, just follow along, you don't really need to know anything about Natural Language Processing to understand this example.\n",
    "\n",
    "If you get interested by the subject, you should start by studying what [word vectors](https://en.wikipedia.org/wiki/Word_embedding) are. I like [this article](https://medium.com/@jayeshbahire/introduction-to-word-vectors-ea1d4e4b84bf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, wait\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# used for multithread file processing\n",
    "def process_vector(line, wordVec_dict, embedding, idx2word):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    wordVec_dict[word] = vec\n",
    "    embedding.append(vec)\n",
    "    idx2word.append(word)\n",
    "\n",
    "class GloveVectorizer:\n",
    "    def __init__(self, multithread=False, workers=10):\n",
    "    # load in pre-trained word vectors\n",
    "    # which is just a space-separated text file in the format:\n",
    "    # word vec[0] vec[1] vec[2] ...\n",
    "        print('Loading word vectors...')\n",
    "        wordVec_dict = {}\n",
    "        embedding = []\n",
    "        idx2word = []\n",
    "    \n",
    "        time_init = time.time()\n",
    "        if multithread:\n",
    "            executor = ThreadPoolExecutor(max_workers=workers)\n",
    "            futures = []\n",
    "            with zipfile.ZipFile('data/glove.6B.50d.txt.zip') as zf:\n",
    "                with io.TextIOWrapper(zf.open('glove.6B.50d.txt'), encoding='utf-8', errors='ignore') as f:\n",
    "                    for line in f:\n",
    "                        futures.append(executor.submit(process_vector, line, wordVec_dict, embedding, idx2word))\n",
    "            for future in as_completed(futures):\n",
    "                pass\n",
    "        else:   \n",
    "            with zipfile.ZipFile('data/glove.6B.50d.txt.zip') as zf:\n",
    "                with io.TextIOWrapper(zf.open('glove.6B.50d.txt'), encoding='utf-8', errors='ignore') as f:\n",
    "                    for line in f:\n",
    "                        values = line.split()\n",
    "                        word = values[0]\n",
    "                        vec = np.asarray(values[1:], dtype='float32')\n",
    "                        wordVec_dict[word] = vec\n",
    "                        embedding.append(vec)\n",
    "                        idx2word.append(word)\n",
    "            \n",
    "        time_end = time.time()\n",
    "        print(f'Found {len(wordVec_dict)} word vectors in {time_end - time_init}s.')\n",
    "\n",
    "        self.wordVec_dict = wordVec_dict\n",
    "        self.embedding = np.array(embedding)\n",
    "        self.word2idx = {v:k for k,v in enumerate(idx2word)}\n",
    "        self.V, self.D = self.embedding.shape\n",
    "\n",
    "\n",
    "    def transform(self, data):\n",
    "        X = np.zeros((len(data), self.D))\n",
    "        n = 0\n",
    "        emptycount = 0\n",
    "        for sentence in data:\n",
    "            tokens = sentence.lower().split()\n",
    "            vecs = []\n",
    "            for word in tokens:\n",
    "                if word in self.wordVec_dict:\n",
    "                    vec = self.wordVec_dict[word]\n",
    "                    vecs.append(vec)\n",
    "            if len(vecs) > 0:\n",
    "                vecs = np.array(vecs)\n",
    "                X[n] = vecs.mean(axis=0)\n",
    "            else:\n",
    "                emptycount += 1\n",
    "            n += 1\n",
    "        print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on\n",
    "\n",
    "We will train a text classificator with `scikit-learn` using data provided from Reuters.\n",
    "The data consists of news texts classified into 8 different labels ([Source](https://www.cs.umb.edu/~smimarog/textmining/datasets/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Vectorizing\n",
    "\n",
    "We will use a pre-trained set of [GloVe](https://nlp.stanford.edu/projects/glove/) word vectors.\n",
    "\n",
    "That's where we can profit from using `multithreading`.\n",
    "Loading this pre-trained word vector file can take a lot of time. The file is considerably big, and we have to process it line per line. Each line contains a word and then a list of values for each dimension of its word vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GloveVectorizer object loads the pre-trained file.\n",
    "Let's start by creating with no `multithreading`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n"
     ]
    }
   ],
   "source": [
    "vectorizer = GloveVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That too some time. In a MacBook Air 2019 this was the output from that last cell:\n",
    "```\n",
    "Loading word vectors...\n",
    "Found 400000 word vectors in 269.19898986816406s.\n",
    "```\n",
    "Now let's see how much time it takes if we use multithreading (check the `__init__` class code if you are interested in how I've implemented it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors in 27.559515953063965s.\n"
     ]
    }
   ],
   "source": [
    "vectorizer = GloveVectorizer(multithread=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. Much faster, right?\n",
    "In a MacBook Air 2019 this was the output from multithreaded execution:\n",
    "```\n",
    "Loading word vectors...\n",
    "Found 400000 word vectors in 27.559515953063965s.\n",
    "```\n",
    "\n",
    "Notice that in this case we could make good use of `multithreading` because the code takes great advantage of async execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading the data into dataframes. No need to use multiprocessing nor multithreading here, as reading CSVs into pandas dataframes is stupid fast.\n",
    "\n",
    "Then we vectorize the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of samples with no words found: 0 / 5485\n",
      "Numer of samples with no words found: 0 / 2189\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/r8-train-all-terms.txt', header=None, sep='\\t')\n",
    "test = pd.read_csv('data/r8-test-all-terms.txt', header=None, sep='\\t')\n",
    "train.columns = ['label', 'content']\n",
    "test.columns = ['label', 'content']\n",
    "\n",
    "Xtrain = vectorizer.transform(train.content)\n",
    "Ytrain = train.label\n",
    "Xtest = vectorizer.transform(test.content)\n",
    "Ytest = test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the cool part: training and testing.\n",
    "\n",
    "Luckly for us,`scikit-learn` offers `multiprocessing` nativelly, just by setting it up on the model's parameters.\n",
    "The following cell will train a same model with the same data using different number of jobs (jobs are mapped to processes in `scikit-learn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9992707383773929\n",
      "test score: 0.9346733668341709\n",
      "Serial training took 6.164580821990967s.\n",
      "Multiprocessing training with 2 processes took 3.465038776397705s.\n",
      "Multiprocessing training with 4 processes took 2.760185956954956s.\n",
      "Multiprocessing training with 8 processes took 2.872230291366577s.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the model, train it, print scores\n",
    "times = []\n",
    "\n",
    "time_init = time.time()\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))\n",
    "time_end = time.time()\n",
    "times.append(float(time_end - time_init))\n",
    "print(f'Serial training took {time_end - time_init}s.')\n",
    "\n",
    "time_init = time.time()\n",
    "model = RandomForestClassifier(n_estimators=200, n_jobs=2)\n",
    "model.fit(Xtrain, Ytrain)\n",
    "time_end = time.time()\n",
    "times.append(float(time_end - time_init))\n",
    "print(f'Multiprocessing training with 2 processes took {time_end - time_init}s.')\n",
    "\n",
    "time_init = time.time()\n",
    "model = RandomForestClassifier(n_estimators=200, n_jobs=4)\n",
    "model.fit(Xtrain, Ytrain)\n",
    "time_end = time.time()\n",
    "times.append(float(time_end - time_init))\n",
    "print(f'Multiprocessing training with 4 processes took {time_end - time_init}s.')\n",
    "\n",
    "time_init = time.time()\n",
    "model = RandomForestClassifier(n_estimators=200, n_jobs=8)\n",
    "model.fit(Xtrain, Ytrain)\n",
    "time_end = time.time()\n",
    "times.append(float(time_end - time_init))\n",
    "print(f'Multiprocessing training with 8 processes took {time_end - time_init}s.')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.set_xlabel('Number of Processes')\n",
    "ax.set_ylabel('Execution Time [s]')\n",
    "num_threads = ['Serial', '2', '4', '8']\n",
    "ax.bar(num_threads, times)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the image and the timing data speaks by itself. Notice how the speedup stagnates once you reach the number of cores your machine has available (or, of course, a natural plateau)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
