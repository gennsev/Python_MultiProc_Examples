{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Multithreading vs Multiprocessing\n",
    "\n",
    "This notebook presents examples of application of multithreading and multiprocessing in python, their pros and cons, and the most appropriate case scenarios for each.\n",
    "\n",
    "Code is based on examples from [Python Documentation](https://docs.python.org/3/library/concurrent.futures.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "\n",
    "\n",
    "addrs = ['http://www.poatek.com',\n",
    "        'https://www.poatek.com/team/',\n",
    "        'https://www.poatek.com/blog/',\n",
    "        'https://www.poatek.com/our-method/',\n",
    "        'https://www.poatek.com/services/',\n",
    "        'https://en.wikipedia.org/wiki/Main_Page',\n",
    "        'https://www.google.com/',\n",
    "        'https://www.kaggle.com/competitions',\n",
    "        'https://www.amazon.com/charts/mostread/fiction/',\n",
    "        'https://www.amazon.com/charts/mostread/nonfiction',\n",
    "        'https://www.amazon.com/charts/mostsold/nonfiction',\n",
    "        'https://www.amazon.com/charts/mostsold/fiction',\n",
    "        'https://www.nytimes.com',\n",
    "        'https://www.bbc.com/',\n",
    "        'https://www.lemonde.fr',\n",
    "        'https://edition.cnn.com',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multithreading(func, args, workers):\n",
    "    with ThreadPoolExecutor(workers) as ex:\n",
    "        res = ex.map(func, args)\n",
    "    return list(res)\n",
    "\n",
    "\n",
    "def multiprocessing(func, args, workers):\n",
    "    with ProcessPoolExecutor(workers) as ex:\n",
    "        res = ex.map(func, args)\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading: I/O intensive tasks\n",
    "\n",
    "I/O intensive programs can directly benefit from multithreading because their bottlenecks are usually reading and/or writing operations (or downloads in the case of web scrappers, for example).\n",
    "\n",
    "\n",
    "In this example we will test a function that reads webpages and writes them on a local text file (we forced the file to be re-written a number of times to stress the execution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def io_intensive(x):\n",
    "    write_count = 50\n",
    "    with urllib.request.urlopen(addrs[x], timeout=20) as conn:\n",
    "        page = conn.read()\n",
    "        for _ in range(write_count):\n",
    "            with open('output.txt', 'w') as output:\n",
    "                output.write(str(page))\n",
    "\n",
    "def test_io_intensive_threads(thread_count_lst):\n",
    "    times = []\n",
    "    num_tasks = len(addrs)\n",
    "    time_init = time.time()\n",
    "    for i in range(num_tasks): \n",
    "        io_intensive(i)\n",
    "    time_end = time.time()\n",
    "    times.append(float(time_end - time_init))\n",
    "    print(f'Serial execution took {time_end - time_init}s.')\n",
    "    for n_threads in thread_count_lst:\n",
    "        time_init = time.time()\n",
    "        multithreading(io_intensive, range(num_tasks), n_threads)\n",
    "        time_end = time.time()\n",
    "        times.append(float(time_end - time_init))\n",
    "        print(f'Multithreading with {n_threads} threads took {time_end - time_init}s.')\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "times = test_io_intensive_threads([2, 4, 8, 16])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.set_xlabel('Number of Threads')\n",
    "ax.set_ylabel('Execution Time [s]')\n",
    "num_threads = ['1', '2', '4', '8', '16']\n",
    "ax.bar(num_threads, times)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your internet connection is alright you should notice that we were able to reduce considerably the execution time of that code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing: CPU-intensive tasks (MacOS and Linux)\n",
    "\n",
    "\n",
    "Programs that are CPU-bound will benefit from multiprocessing because their bottleneck is time and resources. Image and graphics processing are good examples, as they consist of huge amounts of math operations, that can often be divided into separate tasks because their data is independent. GPUs are the state-of-the-art hardware on this regard, being designed to process large chunks of data in parallel. \n",
    "\n",
    "**If you try to execute this code on windows, you will probably run into the following error:\n",
    "``\n",
    "BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
    "``\n",
    "Check the Windows solution below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intensive(x):\n",
    "    foo = 0\n",
    "    for i in range(10**7):\n",
    "        foo += foo * math.cos(i*math.pi)\n",
    "        \n",
    "def test_compute_intensive():\n",
    "    times = []\n",
    "    num_tasks = 4\n",
    "    time_init = time.time()\n",
    "    for i in range(num_tasks): \n",
    "        compute_intensive(i)\n",
    "    time_end = time.time()\n",
    "    times.append(float(time_end - time_init))\n",
    "    print(f'Serial execution took {time_end - time_init}s.')\n",
    "    n_threads = num_tasks\n",
    "    time_init = time.time()\n",
    "    multithreading(compute_intensive, range(num_tasks), n_threads)\n",
    "    time_end = time.time()\n",
    "    times.append(float(time_end - time_init))\n",
    "    print(f'Multithreading with {n_threads} threads took {time_end - time_init}s.')\n",
    "    n_procs = num_tasks\n",
    "    time_init = time.time()\n",
    "    multiprocessing(compute_intensive, range(num_tasks), n_procs)\n",
    "    time_end = time.time()\n",
    "    times.append(float(time_end - time_init))\n",
    "    print(f'Multiprocessing with {n_procs} processes took {time_end - time_init}s.')\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = test_compute_intensive()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.set_xlabel('Execution')\n",
    "ax.set_ylabel('Execution Time [s]')\n",
    "num_threads = ['Serial', '4 Threads', '4 Processes']\n",
    "ax.bar(num_threads, times)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing: CPU-intensive tasks (Windows)\n",
    "\n",
    "If you try to execute the code above on windows, you will probably run into the following error:\n",
    "``\n",
    "BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
    "``\n",
    "\n",
    "\n",
    "That is because of how Windows handles processes. UNIX operating systems (such as Linux and MacOS) use a function called fork() to create new processes. Windows doesn't have os.fork(), so it tries to emulate it in a very stupid way: it just copies the mother-process.. \n",
    "We have to make some changes to our code to guarantee we can execute it on windows without an error or an infinite loop.\n",
    "Basically, we have to create a way for the the child process to run our desired code again, distinguishing the parent process and the child process. We can do it surrouding our original process with the ``if __name__ == '__main__'`` statement, and putting the worker function in a separate file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, freeze_support\n",
    "import windows_worker_cpu\n",
    "\n",
    "def test_compute_intensive():\n",
    "    times = []\n",
    "    num_tasks = 4\n",
    "    time_init = time.time()\n",
    "    for i in range(num_tasks): \n",
    "        windows_worker_cpu.compute_intensive(i)\n",
    "    time_end = time.time()\n",
    "    times.append(float(time_end - time_init))\n",
    "    print(f'Serial execution took {time_end - time_init}s.')\n",
    "    n_threads = num_tasks\n",
    "    time_init = time.time()\n",
    "    multithreading(windows_worker_cpu.compute_intensive, range(num_tasks), n_threads)\n",
    "    time_end = time.time()\n",
    "    times.append(float(time_end - time_init))\n",
    "    print(f'Multithreading with {n_threads} threads took {time_end - time_init}s.')\n",
    "    n_procs = num_tasks\n",
    "    time_init = time.time()\n",
    "    multiprocessing(windows_worker_cpu.compute_intensive, range(num_tasks), n_procs)\n",
    "    time_end = time.time()\n",
    "    times.append(float(time_end - time_init))\n",
    "    print(f'Multiprocessing with {n_procs} processes took {time_end - time_init}s.')\n",
    "    return times\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    times = test_compute_intensive()\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.set_xlabel('Execution')\n",
    "    ax.set_ylabel('Execution Time [s]')\n",
    "    num_threads = ['Serial', '4 Threads', '4 Processes']\n",
    "    ax.bar(num_threads, times)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shall be clear from this example that multithreading just not able to achieve any speedup for this type of application.\n",
    "That is because GIL assures only one thread is executed in the CPU at a given time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing on I/O intensive tasks\n",
    "\n",
    "We have not tested multiprocessing on I/O intesive functions. Even thougt it is, in theory, a waste of resources to dedicate a process to a I/O-bound task, there should be no reason for multiprocessing to be unable to achieve speedups in this use case.\n",
    "\n",
    "Let's check it out:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_io_intensive_processes(proc_count_lst):\n",
    "    times = []\n",
    "    num_tasks = len(addrs)\n",
    "    time_init = time.time()\n",
    "    for i in range(num_tasks): \n",
    "        io_intensive(i)\n",
    "    time_end = time.time()\n",
    "    times.append(float(time_end - time_init))\n",
    "    print(f'Serial execution took {time_end - time_init}s.')\n",
    "    for n_procs in proc_count_lst:\n",
    "        time_init = time.time()\n",
    "        multiprocessing(io_intensive, range(num_tasks), n_procs)\n",
    "        time_end = time.time()\n",
    "        times.append(float(time_end - time_init))\n",
    "        print(f'Multiprocessing with {n_procs} processes took {time_end - time_init}s.')\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = test_io_intensive_processes([2, 4, 8])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.set_xlabel('Number of Processes')\n",
    "ax.set_ylabel('Execution Time [s]')\n",
    "num_threads = ['1', '2', '4', '8']\n",
    "ax.bar(num_threads, times)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, multiprocessing could also deliver speedup for an IO-bound task. You may however notice that threads are still the best option for that case. That is because proccesses have a much higher initialization cost that may compromise their performance. Also, as discussed before, the number of process you can have execution in parallel is limited by the number of processing cores of the machine you are using."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
